{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to train a gradient boosted model to predict whether a donors choose project will be funded or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('bmh')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score,f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features and text data, engineered in previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/main_df.pkl', 'rb') as f:\n",
    "    main_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/word_freqs_titles.pkl', 'rb') as f:\n",
    "    word_freqs_titles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/word_freqs_essays.pkl', 'rb') as f:\n",
    "    word_freqs_essays = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/word_freqs_needs.pkl', 'rb') as f:\n",
    "    word_freqs_needs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine text and non text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "use_in_models = hstack((word_freqs_titles,main_df.drop(['Project ID', 'School ID', 'Teacher ID','Funded?'],axis='columns').values))\n",
    "\n",
    "use_in_models=hstack((use_in_models,word_freqs_essays))\n",
    "\n",
    "use_in_models=hstack((use_in_models,word_freqs_needs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train, validation, and testing sets for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_whole, X_test, y_train_whole, y_test = train_test_split(use_in_models,main_df['Funded?'],\n",
    "                                                  test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_whole,y_train_whole,\n",
    "                                                  test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is shown below. Specific parameters were tuned to achieve best results on validation data. Test data was not used until final iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "gbm = xgb.XGBClassifier( \n",
    "                        n_estimators=30000,\n",
    "                        max_depth=7,\n",
    "                        objective='binary:logistic', #new objective\n",
    "                        learning_rate=.02, \n",
    "                        subsample=.1,\n",
    "                        min_child_weight=4,\n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight=3.67\n",
    "                       )\n",
    "\n",
    "eval_set=[(X_train,y_train),(X_val,y_val)]\n",
    "fit_model = gbm.fit( \n",
    "                    X_train, y_train, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='logloss', #new evaluation metric: classification error (could also use AUC, e.g.)\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose=False\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_predgbm=gbm.predict(X_val, ntree_limit=gbm.best_ntree_limit)\n",
    "y_train_gbm=gbm.predict(X_train, ntree_limit=gbm.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train GB Accuracy: 0.700386469755304\n",
      "Train GB Recall: 0.7996670294361525\n",
      "Train GB Precision: 0.41515633565502236\n",
      "Train GB F1: 0.5465598427306075\n",
      "Val GB Accuracy: 0.6785737272317693\n",
      "Val GB Recall: 0.7525912456163139\n",
      "Val GB Precision: 0.38949462900471893\n",
      "Val GB F1: 0.5133243559304015\n"
     ]
    }
   ],
   "source": [
    "print(\"Train GB Accuracy: \"+str(accuracy_score(y_train, y_train_gbm)))\n",
    "print(\"Train GB Recall: \"+str(recall_score(y_train, y_train_gbm)))\n",
    "print(\"Train GB Precision: \"+str(precision_score(y_train, y_train_gbm)))\n",
    "print(\"Train GB F1: \"+str(f1_score(y_train, y_train_gbm)))\n",
    "\n",
    "print(\"Val GB Accuracy: \"+str(accuracy_score(y_val, y_predgbm)))\n",
    "print(\"Val GB Recall: \"+str(recall_score(y_val, y_predgbm)))\n",
    "print(\"Val GB Precision: \"+str(precision_score(y_val, y_predgbm)))\n",
    "print(\"Val GB F1: \"+str(f1_score(y_val, y_predgbm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data/gbm_model_3.sav'\n",
    "pickle.dump(fit_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('Data/gbm_model_3.sav', 'rb') as f:\n",
    "    final_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test GB Accuracy: 0.6801570918350629\n",
      "Test GB Recall: 0.7554955808731123\n",
      "Test GB Precision: 0.3937529527981789\n",
      "Test GB F1: 0.5176923999971764\n"
     ]
    }
   ],
   "source": [
    "print(\"Test GB Accuracy: \"+str(accuracy_score(y_test, y_pred_test)))\n",
    "print(\"Test GB Recall: \"+str(recall_score(y_test, y_pred_test)))\n",
    "print(\"Test GB Precision: \"+str(precision_score(y_test, y_pred_test)))\n",
    "print(\"Test GB F1: \"+str(f1_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
